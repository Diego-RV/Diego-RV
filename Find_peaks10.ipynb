{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e28252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pastaq as pq\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbba54f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = [{'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE20_exc0-p1_2.ms2\"},\n",
    "               { 'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE20_exc2-p1_2.ms2\"},\n",
    "               {'raw_path' : r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE20_exc10-p1_2.ms2\"},\n",
    "               {'raw_path' : r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE30_exc0-p1_2.ms2\"},\n",
    "               {'raw_path' : r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE30_exc2-p1_2.ms2\"},\n",
    "               {'raw_path' : r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE30_exc10-p1_2.ms2\"},\n",
    "               {'raw_path' : r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE40_exc0-p1_2.ms2\"},\n",
    "               {'raw_path' : r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE40_exc2-p1_2.ms2\"},\n",
    "               {'raw_path' : r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE40_exc10-p1_2.ms2\"},\n",
    "               {'raw_path' : r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE50_exc0-p1_2.ms2\"},\n",
    "               {'raw_path' : r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE50_exc2-p1_2.ms2\"},\n",
    "               {'raw_path' : r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE50_exc10-p1_2.ms2\"},\n",
    "                {'raw_path' : r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE60_exc0-p1_2.ms2\"},\n",
    "               {'raw_path' : r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE60_exc2-p1_2.ms2\"},\n",
    "               {'raw_path' : r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\raw\\p_CE60_exc10-p1_2.ms2\"},\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf2b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c61321",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_clusters_annotations_csv = pd.read_csv(r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\quant\\feature_clusters_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a317657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import ms_entropy as me\n",
    "\n",
    "def combine_multiple_samples(feature_clusters_annotations_csv, input_files, output_dir):\n",
    "    # Preprocess: build a lookup dictionary to avoid filtering the DataFrame each time\n",
    "    annotations_lookup = defaultdict(list)\n",
    "\n",
    "    for _, row in feature_clusters_annotations_csv.iterrows():\n",
    "        if pd.notnull(row['msms_id']):\n",
    "            key = (row['file_id'], row['msms_id'])\n",
    "            annotations_lookup[key].append(row)\n",
    "\n",
    "    combined_multiple_samples = []\n",
    "\n",
    "    for file in input_files:\n",
    "        if 'stem' not in file:\n",
    "            base_name = os.path.splitext(os.path.basename(file['raw_path']))[0]\n",
    "            file['stem'] = base_name\n",
    "        stem = file['stem']\n",
    "        in_path = os.path.join(output_dir, 'raw', f\"{stem}.ms2\")\n",
    "\n",
    "        if not os.path.exists(in_path):\n",
    "            continue\n",
    "\n",
    "        raw_data = pq.read_raw_data(in_path)\n",
    "\n",
    "        for scan in raw_data.scans:\n",
    "            scan_number = scan.scan_number\n",
    "            key = (stem, scan_number)\n",
    "            annotations = annotations_lookup.get(key)\n",
    "\n",
    "            if not annotations:\n",
    "                continue\n",
    "\n",
    "            ms2_mz = scan.mz\n",
    "            ms2_intensity = scan.intensity\n",
    "            ms2_rt = scan.retention_time\n",
    "\n",
    "            if not ms2_mz or not ms2_intensity or len(ms2_mz) != len(ms2_intensity):\n",
    "                continue\n",
    "\n",
    "            # Convert to numpy array for faster sorting\n",
    "            mz_array = np.array(ms2_mz)\n",
    "            intensity_array = np.array(ms2_intensity)\n",
    "            sorted_indices = np.argsort(mz_array)\n",
    "            mz_intensity_pairs = list(zip(mz_array[sorted_indices], intensity_array[sorted_indices]))\n",
    "            ms2_peaks = np.array(mz_intensity_pairs, dtype=np.float32)\n",
    "\n",
    "            for row in annotations:\n",
    "                combined_multiple_samples.append({\n",
    "                    'cluster_id': row['cluster_id'],\n",
    "                    'file_id': row['file_id'],\n",
    "                    'feature_id': row['feature_id'],\n",
    "                    'peak_id': row['peak_id'],\n",
    "                    'msms_id': row['msms_id'],\n",
    "                    'ms2_rt': ms2_rt,\n",
    "                    'charge_state': row['charge_state'],\n",
    "                    'ms2_peaks' : ms2_peaks\n",
    "                })\n",
    "\n",
    "\n",
    "    return combined_multiple_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe962861",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_multiple_samples = combine_multiple_samples(feature_clusters_annotations_csv, input_files, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "569ec32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = [{'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE20_exc0-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE20_exc2-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE20_exc10-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE30_exc0-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE30_exc2-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE30_exc10-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE40_exc0-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE40_exc2-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE40_exc10-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE50_exc0-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE50_exc2-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE50_exc10-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE60_exc0-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE60_exc2-p1_2.features\"},\n",
    "                {'raw_path': r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\\features\\p_CE60_exc10-p1_2.features\"}\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c95ec1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\pastaq_CID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "290870a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import ms_entropy as me\n",
    "from pathlib import Path\n",
    "\n",
    "# Fast & working!\n",
    "def link_features(combined_multiple_samples, input_files, output_dir):\n",
    "    # Preprocess: build a lookup dictionary to avoid filtering the DataFrame each time\n",
    "    annotations_lookup = defaultdict(list)\n",
    "    linked_features = []\n",
    "\n",
    "    for item in combined_multiple_samples:\n",
    "        if pd.notnull(item['feature_id']):\n",
    "            key = (item['file_id'], item['feature_id'])\n",
    "            annotations_lookup[key].append(item)\n",
    "\n",
    "    for file in input_files:\n",
    "        if 'stem' not in file:\n",
    "            base_name = os.path.splitext(os.path.basename(file['raw_path']))[0]\n",
    "            file['stem'] = base_name\n",
    "        stem = file['stem']\n",
    "        in_path_features = os.path.join(output_dir, 'features', f\"{stem}.features\")\n",
    "\n",
    "        if not os.path.exists(in_path_features):\n",
    "            print('missing feature file/s')\n",
    "            continue\n",
    "\n",
    "        features = pq.read_features(in_path_features)\n",
    "\n",
    "        for feature in features:\n",
    "            id = feature.id\n",
    "            key = (stem, id)\n",
    "            annotations = annotations_lookup.get(key)\n",
    "\n",
    "            if not annotations:\n",
    "                continue\n",
    "\n",
    "            if isinstance(annotations, list):\n",
    "                for annotation in annotations:\n",
    "                    linked_features.append({\n",
    "                        'cluster_id': annotation['cluster_id'],\n",
    "                        'file_id': annotation['file_id'],\n",
    "                        'feature_id': id,\n",
    "                        'feature_peak_ids': feature.peak_ids,\n",
    "                        'peak_id' : annotation['peak_id'],\n",
    "                        'msms_id': annotation['msms_id'],\n",
    "                        'precursor_mz' : feature.monoisotopic_mz,\n",
    "                        'precursor_rt': feature.monoisotopic_rt,\n",
    "                        'precursor_intensity': feature.monoisotopic_height,\n",
    "                        'precursor_vol': feature.monoisotopic_volume,\n",
    "                        'total_intensity': feature.total_height,\n",
    "                        'total_volume': feature.total_volume,\n",
    "                        'average_ms1_mz': feature.average_mz,\n",
    "                        'average_rt': feature.average_rt,\n",
    "                        'charge_state': feature.charge_state,\n",
    "                        'ms2_sample_peaks': annotation['ms2_peaks'],                  \n",
    "                        })\n",
    "\n",
    "    return linked_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71768f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_features = link_features(combined_multiple_samples=combined_multiple_samples, input_files=input_files, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "864cb23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msp_file = r\"C:\\Users\\diego.DESKTOP-7OSFK5B\\Documents\\MSc_Research_Project1\\CID_files\\Msp_CID_2025_03_21_12_30_01_AlignmentResult_2025_03_19_11_06_05.msp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f1d76ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "msp_data = pq.read_msp_file(msp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "827fb6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import ms_entropy as me\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import ast\n",
    "\n",
    "def link_msp(linked_features, msp_data, mz_tolerance=0.025, rt_tolerance=8.0):\n",
    "    linked_msp_features = []\n",
    "\n",
    "    # Loop through a list of Feature objects\n",
    "    for feature in linked_features:\n",
    "        cluster_id = feature['cluster_id']\n",
    "        file_id = feature['file_id']\n",
    "        feature_id = feature['feature_id']\n",
    "        feature_peak_ids = feature['feature_peak_ids']\n",
    "        peak_id = feature['peak_id']\n",
    "        msms_id = feature['msms_id']\n",
    "        precursor_mz = feature['precursor_mz']\n",
    "        precursor_rt = feature['precursor_rt']\n",
    "        precursor_intensity = feature['precursor_intensity']\n",
    "        precursor_volume = feature['precursor_vol']\n",
    "        average_ms1_mz = feature['average_ms1_mz']\n",
    "        average_rt = feature['average_rt']\n",
    "        charge_state = feature['charge_state']\n",
    "        ms2_sample_peaks = feature['ms2_sample_peaks']\n",
    "        total_intensity = feature['total_intensity'] \n",
    "        total_volume = feature['total_volume']                   \n",
    "        normalized_area = precursor_volume * 114.7977026\n",
    "\n",
    "        # Centroid the MS2 spectrum\n",
    "        centroided_peaks = me.clean_spectrum(\n",
    "                    ms2_sample_peaks,\n",
    "                    min_ms2_difference_in_da=0.02,\n",
    "                    normalize_intensity=False\n",
    "                )\n",
    "\n",
    "        centroided_arr = np.array(centroided_peaks)\n",
    "        centroided_arr_list = centroided_arr.tolist()\n",
    "\n",
    "        # Find all matching annotations for the current scan\n",
    "        best_match = None  # To store the best match found\n",
    "\n",
    "        for annotation in msp_data:\n",
    "            # Ensure required fields are present in the annotation\n",
    "            if 'precursor_mz' not in annotation or 'retention_time' not in annotation:\n",
    "                continue  # Skip this annotation\n",
    "\n",
    "            # Calculate mz and rt distances directly for scalars\n",
    "            mz_distance = np.abs(precursor_mz - annotation['precursor_mz']) # changed this from 'mz' to 'precursor_mz'\n",
    "            rt_distance = np.abs(precursor_rt - annotation['retention_time'])  # changed this from 'retention_time' to 'precursor_rt' \n",
    "\n",
    "            # Apply the tolerance checks\n",
    "            if mz_distance <= mz_tolerance and rt_distance <= rt_tolerance:\n",
    "                # If the distances are within tolerance, calculate the match score with normalization factor\n",
    "                match_score = (rt_distance*0.025) + (mz_distance*20) # lower score is better/ closer match; added weighting\n",
    "                \n",
    "                # Calculate mass error in ppm using formula\n",
    "                mass_error_ppm = ((annotation['precursor_mz'] - precursor_mz) / annotation['precursor_mz']) * 10**6\n",
    "                \n",
    "                #Calculate root mean squared error for best match\n",
    "                y_true_mz = [annotation.get('precursor_mz')]\n",
    "                y_pred_mz = [precursor_mz]\n",
    "                rmse_mz = root_mean_squared_error(y_true_mz, y_pred_mz)\n",
    "\n",
    "                # Convert peaks to numpy arrays for similarity calculation (MS_Entropy)\n",
    "                peaks_query = np.array(ms2_sample_peaks, dtype=np.float32) #peaks from given samples\n",
    "                peaks_reference = np.array([annotation.get('peaks')], dtype=np.float32)  # peaks from msp\n",
    "                if peaks_reference.ndim == 3 and peaks_reference.shape[0] == 1:\n",
    "                    peaks_reference = peaks_reference[0]  # remove the first singleton dimension\n",
    "                    \n",
    "                # Calculate similarity scores (MS_entropy)\n",
    "                unweighted_similarity = me.calculate_unweighted_entropy_similarity(peaks_query, peaks_reference)\n",
    "                similarity = me.calculate_entropy_similarity(peaks_query, peaks_reference) # entropy based intensity weights are applied to the peaks\n",
    "\n",
    "                # Extract m/z and intensity values\n",
    "                reference_mz, reference_intensity = zip(*peaks_reference)\n",
    "\n",
    "                # Convert to NumPy arrays\n",
    "                # Parse the mz and intensity arrays\n",
    "                sample_mz, sample_intensity = zip(*centroided_peaks)\n",
    "                sample_mz = np.array(sample_mz)\n",
    "                sample_intensity = np.array(sample_intensity, dtype=np.float32)\n",
    "                reference_mz = np.array(reference_mz)\n",
    "                reference_intensity = np.array(reference_intensity, dtype=np.float32)\n",
    "\n",
    "                # Match peaks based on m/z values\n",
    "                matched_indices = np.searchsorted(reference_mz, sample_mz)\n",
    "\n",
    "                # Ensure indices are within bounds (removes any indices that are out of bounds)\n",
    "                matched_indices = matched_indices[matched_indices < len(reference_mz)]\n",
    "\n",
    "                # Example mass spectra intensities\n",
    "                sample_spectrum = np.array(sample_intensity[:len(matched_indices)])\n",
    "                reference_spectrum = np.array(reference_intensity[matched_indices])\n",
    "\n",
    "                # Normalize both vectors to unit length (L2 norm)\n",
    "                sample_spectrum_normalized = sample_spectrum / np.linalg.norm(sample_spectrum)\n",
    "                reference_spectrum_normalized = reference_spectrum / np.linalg.norm(reference_spectrum)\n",
    "\n",
    "                # Compute dot product (cosine similarity if normalized)\n",
    "                if len(sample_intensity) < 3 or len(reference_intensity) < 3:\n",
    "                    dot_product = None\n",
    "                else:\n",
    "                    dot_product = np.dot(sample_spectrum_normalized, reference_spectrum_normalized)\n",
    "                \n",
    "                if best_match is None or match_score < best_match['score']:\n",
    "                    best_match = {\n",
    "                        'score': float(match_score),  # Store the match score\n",
    "                        'name': annotation.get('name', None),\n",
    "                        'saturation' : annotation.get('saturation', None),\n",
    "                        'retention_time': annotation.get('retention_time', None),\n",
    "                        'precursor_mz': annotation.get('precursor_mz', None),\n",
    "                        'precursor_type': annotation.get('precursor_type', None),\n",
    "                        'smiles': annotation.get('smiles', None),\n",
    "                        'msp_peaks': annotation.get('peaks', None),\n",
    "                    }\n",
    "        \n",
    "                    # Create the annotated scan with only the best match\n",
    "                    linked_msp_feature = {\n",
    "                        'cluster_id' : cluster_id,\n",
    "                        'file_id' : file_id,\n",
    "                        'peak_id': peak_id,\n",
    "                        'msms_id' : msms_id,\n",
    "                        'average_ms1_mz': average_ms1_mz,\n",
    "                        'total_intensity': total_intensity,  # Intensity values\n",
    "                        'average_rt': average_rt,  # Average retention time (in seconds)\n",
    "                        'total_volume' : total_volume,\n",
    "                        'precursor_mz': precursor_mz,\n",
    "                        'precursor_intensity' : precursor_intensity,\n",
    "                        'precursor_rt' : precursor_rt,\n",
    "                        'precursor_volume' : precursor_volume,\n",
    "                        'normalized_area' : normalized_area,\n",
    "                        'charge_state' : charge_state,\n",
    "                        'feature_id': feature_id,\n",
    "                        'feature_peak_ids' : feature_peak_ids,\n",
    "                        'centroided_ms2_peaks' : centroided_arr_list,\n",
    "                        'mass_error_ppm' : float(mass_error_ppm),\n",
    "                        'rmse_mz' : float(rmse_mz),\n",
    "                        'unweighted_entropy_similarity' : unweighted_similarity,\n",
    "                        'entropy_similarity' : similarity,\n",
    "                        'dot_product': float(dot_product) if dot_product is not None else 'NA',\n",
    "                        'matches': []  # List to hold the top match\n",
    "                        }\n",
    "\n",
    "        # Add the best match if available\n",
    "        if best_match:\n",
    "            linked_msp_feature['matches'].append(best_match)\n",
    "        else:\n",
    "            linked_msp_feature['matches'] = None  # No match found\n",
    "        \n",
    "        linked_msp_features.append(linked_msp_feature)\n",
    "\n",
    "    # Return after all features are processed\n",
    "    return linked_msp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6589a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_msp = link_msp(linked_features, msp_data, mz_tolerance=0.025, rt_tolerance=8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "525cf54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "filepath = Path('CID_metadata/CID_CORRECT/linked_msp.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "linked_msp_df = pd.DataFrame(linked_msp)\n",
    "linked_msp_df.to_csv(Path('CID_metadata/CID_CORRECT/linked_msp.csv', index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PASTAQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
